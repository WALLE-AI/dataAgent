# dataAgent
* dataAgent 构建数据图文数据集、SFT数据集和DPO数据集

## 参考文献
* 问答数据构建框架 | SciQAG:一个具有细粒度评估的自动生成科学问答数据集的框架 https://yiyibooks.cn/arxiv/2405.09939v1/index.html
* On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey
* https://github.com/HqWu-HITCS/Awesome-Chinese-LLM
* How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources
* https://github.com/WorkInTheDark/FairytaleQA_QAG_System
* https://github.com/sugyeonge/Towards-diverse-QAG
* 吴恩达老师帮我构造指令微调（SFT）数据｜从零手搓中文大模型｜
* 如何获取高质量数据进行代码指令调优？
* 【LLM数据工程】LLMs-数据构造-Self-Instruct总结v3.0
* 大模型微调的终极指南：从基础到突破的详尽综述，这个特别值得一看，《The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities》：https://arxiv.org/pdf/2408.13296
* 智源千万级指令微调数据集 Infinity-Instruct 持续迭代
* 【LLM模型微调】LLMs-数据构造-LIMA-论文总结v3.0
* https://github.com/svjack/docvqa-gen
* https://github.com/percent4/embedding_rerank_retrieval embedding模型微调
* https://github.com/Steven-Luo/MasteringRAG/blob/main/00_PDF%E8%A7%A3%E6%9E%90%E4%B8%8EQA%E6%8A%BD%E5%8F%96_v1.1.ipynb embedding 微调
* https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html 知识蒸馏
* Online DPO: Online Direct Preference Optimization with Fast-Slow Chasin
* https://data-people-group.github.io/blogs/2024/09/24/docetl/
